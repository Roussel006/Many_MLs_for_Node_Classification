{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Experiments with Deep Learning Models\n",
    "\n",
    "In this section, we build five Deep Learning models, using **Tensorflow**. Later, we will see how to build the same models to PyTorch and learn how to translate models between Tensorflow and PyTorch.\n",
    "\n",
    "    2a. A simple dense model: with only pooling layer between the input and the output layers.\n",
    "    2b. A deeper model with more layers\n",
    "    2c. An Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM)\n",
    "    2d. An RNN with Gated Recurrent Unit (GRU)\n",
    "    2e. A Convolutional Neural Network (CNN)\n",
    "\n",
    "\n",
    "**The Dataset** we will use is the CiteSeer Dataset and classify the documents or the nodes. This dataset is a popular benchmark for Graph-based MLs. As of January 2025, the best accuracy achieved is **82.07 Â± 1.04** by [\"ACMII-Snowball-2\"](https://paperswithcode.com/paper/is-heterophily-a-real-nightmare-for-graph). A live update on the rankings can be found in this [link](https://paperswithcode.com/sota/node-classification-on-citeseer).\n",
    "\n",
    "Can we beat it? Perhaps not so easily, as brilliant ML scientists and engineers have already thrown the kitchen sink at it. But we can definitely try! Why not dream? We will see how close we can get.\n",
    "\n",
    "The information within the dataset: This dataset contains a set of 3327 scientific papers represented by binary vectors of 3703 words, with the values represent the presence or absence of the words in the document. A **key feature** of the dataset is that it also contains data on the citations among the papers as a citation graph or network, along with the text data. Here we are only use the text data. In later sections, we will incorporate the Graph data and see how it changes things. The availability of both types of data is the biggest reason we picked this dataset.\n",
    "\n",
    "**The General Plan**:\n",
    "1. <u>Build our Deep Learning models</u>: For each model, we will set up all layers between the inputs and the outputs. Some layers after the input layer may be for processing the text data and convert them to numbers -- such as, tokenizing/vectorizing and embedding. Then, we may have a convolutional or a recurrent layer. We may as well have pooling in between to reduce dimensionality of the vectors. Finally, as a we have a multi-class classification at hand, we will use the softmax function at the output layer.\n",
    "\n",
    "2. <u>Train, Validate, and Test</u>: After training, we will check the validation and the test accuracies. \n",
    "\n",
    "3. <u>Save the Models</u>: We will then save the models so that we can call them up again in later sections.\n",
    "\n",
    "It is almost as simple as it sounds. Of course, there are some nuances to these methods. But, we do not need to worry too much about it now. We will discuss things as they become necessary.\n",
    "\n",
    "Finally, a big thanks to [Daniel Bourke](https://github.com/mrdbourke) for his awesome, student-friendly courses on Deep Learning, which helped me a lot in building the models in this section. Please consider taking his courses if you want a more detailed understanding of the deep learning models here.\n",
    "\n",
    "Enough talking! Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing, get some essential Packages\n",
    "# We also create a new directory to save the models\n",
    "\n",
    "# Numpy for matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "# Visualization\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# NO NEED FOR THE FOLLOWING AS IMPLEMENTED IN THE TENSORBOARD_CALLBACKS\n",
    "# Define the name of the directory to be created\n",
    "# directory_name = \"Saved_ML_models_Exp2\"\n",
    "\n",
    "# # Get the current working directory\n",
    "# current_working_directory = os.getcwd()\n",
    "# # Create the full path for the new directory\n",
    "# new_directory_path = os.path.join(current_working_directory, directory_name)\n",
    "\n",
    "# # Check if the directory exists, and create it if it does not\n",
    "# if not os.path.exists(new_directory_path):\n",
    "#     os.makedirs(new_directory_path)\n",
    "#     print(f\"Directory '{directory_name}' created at {new_directory_path}\")\n",
    "# else:\n",
    "#     print(f\"Directory '{directory_name}' already exists at {new_directory_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the CiteSeer Dataset\n",
    "This dataset is available through PyTorch Geometric, a package dedicated to Graph NNs. The CiteSeer is one of the several datasets available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# Import dataset from PyTorch Geometric\n",
    "dataset = Planetoid(root=\".\", name=\"CiteSeer\")\n",
    "\n",
    "data = dataset[0] # We extract the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: CiteSeer()\n",
      "Input Text Data shape: torch.Size([3327, 3703])\n",
      "First five rows of the text data:\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "print(\"Dataset name:\", dataset)\n",
    "print(\"Input Text Data shape:\", data.x.shape)\n",
    "print(\"First five rows of the text data:\\n\", data.x[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the dataset has 3327 documents as rows, made up of 3703 unique words. The documents are represented as one-hot vectors of length 3703. One hot vectors simply mean that if a word exists, then we assign it's magnitude to be 1 and if not, then we assign the magnitude to be 0. We just to need to follow the same order of words for each document, and that is it.\n",
    "\n",
    "An interesting point is the array type, which is \"torch.tensor\". Torch tensors are perfectly compatible with Numpy, so we should be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Please note that we are not using all of the data available, rather using only about half of the documents. Moreover, we are using just 120 documents for training. The reason is that these are stipulations imposed in benchmarking different models that we saw earlier. We keep the split as is to be able to compare with the state-of-the-art results.\n",
    "\n",
    "Now, we are ready to get modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 2: Deep Learning Models\n",
    "\n",
    "In the next block, we load all the packages we would need. We create a function to calculate different types of accuracies between the true labels and the predicted labels. In this work, we will use some \"helper\" functions (such as \"create_tensorboard_callback\" and \"unzip_data\") developed by Daniel Bourke. Please see [here](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py) for the functions and to modify as necessary. In the codes below, we also specify a directory to save our models and their checkpoints -- which we will see shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-01-18 14:05:10--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10246 (10K) [text/plain]\n",
      "Saving to: 'helper_functions.py.4'\n",
      "\n",
      "     0K ..........                                            100% 15.3M=0.001s\n",
      "\n",
      "2025-01-18 14:05:10 (15.3 MB/s) - 'helper_functions.py.4' saved [10246/10246]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pickle # For saving models\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "# Calculate model accuracy\n",
    "# Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \n",
    "# y_true: true labels in the form of a 1D array\n",
    "# y_pred: predicted labels in the form of a 1D array\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "    return(model_results)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n",
    "\n",
    "# Create directory to save TensorBoard checkpoints and entire models\n",
    "SAVE_DIR_for_checkpoints = \"Saved_DL_models_Exp2/Model_checkpoints\"\n",
    "SAVE_DIR_for_entire_models = \"Saved_DL_models_Exp2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Texts in two steps\n",
    "### Tokenizing\n",
    "\n",
    "<!-- (Need to functionize the whole thing, a little left to do.) -->\n",
    "\n",
    "Tokenizing simply means assigning each unique word in a set of documents a unique token or an ID and then representing the docs as lists of tokens or numbers uniquely assigned to the words. The tokens allows us to represent the docs as vectors with the dimensions of words or their tokens. A related step we complete here is to \"pad\" the vectors, which simply makes the vectors the same size, by adding zeros to the end. Please see the below printout for an example. The tokenized vectors would be then used to create embeddings, which we look into in the next section.\n",
    "\n",
    "We have a binary (one-hot encoded) version of the documents at hand. This representation is essentially a form of vector representation we could use directly. However, we need the tokenized version from the one-hot encoded version as we want to use an embedding layer from Tensorflow which works better on tokenized documents. We tried using Tensorflow's tokenizer function to tokenize, but it did not work so well with our one-hot encoded data. It was easier to do the tokenizing ourselves than trying to fix it.\n",
    "\n",
    "The below function tokenizes the words with numbers from the range (1, max number of tokens). We leave 0 out as a token, rather the vectors padded with 0s to make equal size for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3046^{th} item: current_length == desired_length. So did nothing.\n",
      "\n",
      "First two documents:\n",
      " [[ 185  258  363  561  566  598  601  602  638  730  806  817  943 1117\n",
      "  1436 1546 1624 1636 1847 2086 2339 2344 2566 2605 2697 2742 2919 2971\n",
      "  3503 3549 3648    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  83  103  115  418  654  798  806  832  850  893 1074 1084 1166 1289\n",
      "  1954 2437 2511 2734 2742 2880 2910 2931 3017 3127 3161 3229 3255 3331\n",
      "  3365 3448 3462 3640 3641    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences_upto_a_certain_length(i, x, desired_length):\n",
    "    x = list(x)\n",
    "    current_length = len(x)\n",
    "    if current_length < desired_length:\n",
    "        x[current_length: ] = np.zeros(desired_length - current_length, dtype = int)\n",
    "    elif (current_length == desired_length):\n",
    "        print(\"%i^{th} item: current_length == desired_length. So did nothing.\"%i)\n",
    "    elif (current_length > desired_length):\n",
    "        print(\"%i^{th} item: current_length > desired_length. Shouldn't happen. Please check\"%i, current_length, desired_length)\n",
    "    return(x)\n",
    "\n",
    "# How many words are there in the document with the most words? We will pad the vectors upto that length.\n",
    "max_tokens = int(data.x.sum(axis= 1).max())\n",
    "\n",
    "temp_x = [np.argwhere(data.x[i, :]>0)+1 for i in range(data.x.shape[0])] # add 1 as we do not want to use 0 as a token. We will use it for padding.\n",
    "temp_x = [i.squeeze().tolist() for i in temp_x]\n",
    "\n",
    "padded_x = [pad_sequences_upto_a_certain_length(i_item, temp_x[i_item], desired_length = max_tokens) for i_item in range(len(temp_x))]\n",
    "padded_x = np.array(padded_x) # np arrays would allow using the data masks\n",
    "\n",
    "print(\"\\nFirst two documents:\\n\", padded_x[0:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "After tokenizing, we come to embed our vectors. In the last part, after tokenizing, we discussed representing *each document* as a vector of the tokens or the words. In contrast, the process of embedding turn *each word* into a vector in a latent space. The embeddings allow models to understand the relationships between words based on their context and usage in the text. Popular methods for generating embeddings include Word2Vec, GloVe, and BERT.\n",
    "\n",
    "In summary, tokenizing breaks text into pieces, and embedding transforms those pieces into numerical representations that capture their meanings. This combination is fundamental for many NLP tasks.\n",
    "\n",
    "Below, we set up the embedding layer. The max vocab length is usually equal to or less than the total number of words. We set the length to be 10 higher than the total number of unique words as a cushion to ensure we are indeed taking all words into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = data.x.shape[1] + 10 # Total number of words + 10 for some cushion as unsure whether the padding token (\"0\") must be accounted for here.\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=None, # how long is each input\n",
    "                             name=\"embedding_1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Splitting\n",
    "We already have the mask values in the dataset. We just use them to split it as necessary. As these input data is in one_hot format, we add a subscript here. Later, we will use a list of tokens/features representation, so the distinction may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 54) (500, 54) (1000, 54)\n"
     ]
    }
   ],
   "source": [
    "train_sentences = padded_x[data.train_mask]\n",
    "train_labels = data.y[data.train_mask]\n",
    "\n",
    "val_sentences = padded_x[data.val_mask]\n",
    "val_labels = data.y[data.val_mask]\n",
    "\n",
    "test_sentences = padded_x[data.test_mask]\n",
    "test_labels = data.y[data.test_mask]\n",
    "\n",
    "print(train_sentences.shape, val_sentences.shape, test_sentences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2a: A not-so-deep deep learning model\n",
    "\n",
    "Between the input and the output layers, we just the embedding layer followed by a average pooling layer.\n",
    "\n",
    "With this simple model, we will also see how to save (1) model checkpoints and (2) the entire model. We save the model check points with tensorboard_callback, WHILE FITTING THE MODEL (Step 3). For this step, we use a convenient \"helper\" function -- \"create_tensorboard_callback\" -- developed by Daniel Bourke. Please see [here](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py) for the functions and to modify as necessary. After the model is fit, we save the model (Step 4). We use the new \".keras\" format. Please see [here](https://www.tensorflow.org/tutorials/keras/save_and_load) for details and for the legacy save formats (i.e., .h5 and SavedModel) All checkpoints and the model are saved in the directory we had specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 54, 128)\n",
      "(None, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2a\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2a\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling1d_8      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling1d_8      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m774\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,038</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m476,038\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,038</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m476,038\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: Saved_DL_models_Exp2/Model_checkpoints/Model_2a/20250118-140716\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1629 - loss: 1.7587 - val_accuracy: 0.3560 - val_loss: 1.7530\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3640 - loss: 1.6731 - val_accuracy: 0.4080 - val_loss: 1.7392\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6304 - loss: 1.5938 - val_accuracy: 0.4540 - val_loss: 1.7260\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6719 - loss: 1.5170 - val_accuracy: 0.4720 - val_loss: 1.7132\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7013 - loss: 1.4425 - val_accuracy: 0.4860 - val_loss: 1.7007\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8542 - loss: 1.3703 - val_accuracy: 0.4900 - val_loss: 1.6886\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9056 - loss: 1.3005 - val_accuracy: 0.5000 - val_loss: 1.6767\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9915 - loss: 1.2332 - val_accuracy: 0.5120 - val_loss: 1.6652\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1684 - val_accuracy: 0.5180 - val_loss: 1.6539\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1063 - val_accuracy: 0.5320 - val_loss: 1.6430\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0469 - val_accuracy: 0.5300 - val_loss: 1.6324\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.9902 - val_accuracy: 0.5240 - val_loss: 1.6221\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.9362 - val_accuracy: 0.5300 - val_loss: 1.6122\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.8850 - val_accuracy: 0.5340 - val_loss: 1.6026\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.8364 - val_accuracy: 0.5340 - val_loss: 1.5933\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.7904 - val_accuracy: 0.5380 - val_loss: 1.5843\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.7471 - val_accuracy: 0.5340 - val_loss: 1.5756\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.7062 - val_accuracy: 0.5300 - val_loss: 1.5673\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.6677 - val_accuracy: 0.5320 - val_loss: 1.5592\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.6316 - val_accuracy: 0.5280 - val_loss: 1.5515\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.5976 - val_accuracy: 0.5300 - val_loss: 1.5440\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.5658 - val_accuracy: 0.5260 - val_loss: 1.5367\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.5359 - val_accuracy: 0.5280 - val_loss: 1.5297\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.5080 - val_accuracy: 0.5300 - val_loss: 1.5230\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4818 - val_accuracy: 0.5360 - val_loss: 1.5165\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4573 - val_accuracy: 0.5340 - val_loss: 1.5102\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4343 - val_accuracy: 0.5320 - val_loss: 1.5041\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4128 - val_accuracy: 0.5300 - val_loss: 1.4982\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.3927 - val_accuracy: 0.5260 - val_loss: 1.4925\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.3738 - val_accuracy: 0.5300 - val_loss: 1.4869\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.3562 - val_accuracy: 0.5280 - val_loss: 1.4816\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.3396 - val_accuracy: 0.5320 - val_loss: 1.4764\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.3241 - val_accuracy: 0.5320 - val_loss: 1.4714\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.3095 - val_accuracy: 0.5320 - val_loss: 1.4666\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.2958 - val_accuracy: 0.5320 - val_loss: 1.4619\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2829 - val_accuracy: 0.5340 - val_loss: 1.4574\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2708 - val_accuracy: 0.5380 - val_loss: 1.4530\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.2594 - val_accuracy: 0.5380 - val_loss: 1.4488\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2487 - val_accuracy: 0.5380 - val_loss: 1.4447\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.2386 - val_accuracy: 0.5380 - val_loss: 1.4407\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2291 - val_accuracy: 0.5380 - val_loss: 1.4369\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.2201 - val_accuracy: 0.5340 - val_loss: 1.4332\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2116 - val_accuracy: 0.5360 - val_loss: 1.4296\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2036 - val_accuracy: 0.5340 - val_loss: 1.4261\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1960 - val_accuracy: 0.5360 - val_loss: 1.4227\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1888 - val_accuracy: 0.5360 - val_loss: 1.4194\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1820 - val_accuracy: 0.5360 - val_loss: 1.4163\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1755 - val_accuracy: 0.5360 - val_loss: 1.4132\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1694 - val_accuracy: 0.5360 - val_loss: 1.4102\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1636 - val_accuracy: 0.5340 - val_loss: 1.4073\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 53.400000000000006, 'precision': 0.6055502849350548, 'recall': 0.534, 'f1': 0.5577202632409117}\n",
      "{'accuracy': 53.900000000000006, 'precision': 0.5903131105101898, 'recall': 0.539, 'f1': 0.5555557800964094}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define or Build Model -- Define its layers (input, hidden layers, output)\n",
    "input_length = train_sentences.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_length, ), dtype=\"int\") # inputs are 1-dimensional array of input length\n",
    "x = embedding(inputs) # create an embedding of the numerized numbers\n",
    "print(x.shape)\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "model_2a = tf.keras.Model(inputs, outputs, name=\"model_2a\") # construct the model\n",
    "\n",
    "# 1a. Print a model summary describing the layers and the parameters.\n",
    "model_2a.summary()\n",
    "\n",
    "# 2. Compile model -- set up the loss, optimizer, and accuracy metrics to use in training the model\n",
    "model_2a.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Train or Fit model\n",
    "model_2a_history = model_2a.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=50,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR_for_checkpoints, experiment_name=\"Model_2a\")])\n",
    "\n",
    "# 3a: Test accuracy across sets\n",
    "\n",
    "model_2a_train_pred_probs = model_2a.predict(train_sentences)\n",
    "model_2a_train_preds = tf.argmax(model_2a_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2a_val_pred_probs = model_2a.predict(val_sentences)\n",
    "model_2a_val_preds = tf.argmax(model_2a_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2a_test_pred_probs = model_2a.predict(test_sentences)\n",
    "model_2a_test_preds = tf.argmax(model_2a_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = model_2a_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = model_2a_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = model_2a_test_preds, y_true = test_labels))\n",
    "\n",
    "# 4: Save Model in *.keras format\n",
    "model_2a.save(SAVE_DIR_for_entire_models + \"/Model_2a.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2b: Adding more layers\n",
    "\n",
    "We add a dense layer with 128 neurons, after the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2b\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2b\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling1d_9      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_10 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â        \u001b[38;5;34m16,512\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling1d_9      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_11 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m774\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">492,550</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m492,550\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">492,550</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m492,550\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: Saved_DL_models_Exp2/Model_checkpoints/model_2b/20250118-140722\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.4481 - loss: 1.7432 - val_accuracy: 0.2920 - val_loss: 1.7439\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6890 - loss: 1.4558 - val_accuracy: 0.3680 - val_loss: 1.6932\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2134 - val_accuracy: 0.4640 - val_loss: 1.6490\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0047 - val_accuracy: 0.5000 - val_loss: 1.6088\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.8252 - val_accuracy: 0.5180 - val_loss: 1.5715\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.6723 - val_accuracy: 0.5240 - val_loss: 1.5376\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.5435 - val_accuracy: 0.5380 - val_loss: 1.5067\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.4360 - val_accuracy: 0.5340 - val_loss: 1.4792\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.3481 - val_accuracy: 0.5340 - val_loss: 1.4556\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2778 - val_accuracy: 0.5340 - val_loss: 1.4353\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2228 - val_accuracy: 0.5320 - val_loss: 1.4182\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1801 - val_accuracy: 0.5280 - val_loss: 1.4036\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1473 - val_accuracy: 0.5240 - val_loss: 1.3908\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1219 - val_accuracy: 0.5260 - val_loss: 1.3794\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1022 - val_accuracy: 0.5280 - val_loss: 1.3691\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0869 - val_accuracy: 0.5280 - val_loss: 1.3597\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0747 - val_accuracy: 0.5320 - val_loss: 1.3511\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 0.5300 - val_loss: 1.3435\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 0.5280 - val_loss: 1.3366\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 0.5320 - val_loss: 1.3304\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 0.5320 - val_loss: 1.3249\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0413 - val_accuracy: 0.5320 - val_loss: 1.3200\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.5320 - val_loss: 1.3156\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 0.5340 - val_loss: 1.3118\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.5340 - val_loss: 1.3083\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 0.5360 - val_loss: 1.3052\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.5360 - val_loss: 1.3024\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.5360 - val_loss: 1.2999\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.5340 - val_loss: 1.2975\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.5360 - val_loss: 1.2954\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.5380 - val_loss: 1.2934\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.5380 - val_loss: 1.2915\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.5360 - val_loss: 1.2897\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.5360 - val_loss: 1.2881\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.5340 - val_loss: 1.2865\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.5340 - val_loss: 1.2850\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.5340 - val_loss: 1.2836\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.5340 - val_loss: 1.2823\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.5320 - val_loss: 1.2811\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.5320 - val_loss: 1.2799\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5320 - val_loss: 1.2788\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5320 - val_loss: 1.2777\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5320 - val_loss: 1.2768\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.5340 - val_loss: 1.2758\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5380 - val_loss: 1.2750\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.5380 - val_loss: 1.2741\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.5380 - val_loss: 1.2734\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5380 - val_loss: 1.2726\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.5380 - val_loss: 1.2719\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.5380 - val_loss: 1.2713\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 53.800000000000004, 'precision': 0.5840065100078927, 'recall': 0.538, 'f1': 0.5520366322135091}\n",
      "{'accuracy': 55.300000000000004, 'precision': 0.5842542878072893, 'recall': 0.553, 'f1': 0.5631220520975795}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define or Build Model -- Define its layers (input, hidden layers, output)\n",
    "input_length = train_sentences.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_length, ), dtype=\"int\") # inputs are 1-dimensional array of input length\n",
    "x = embedding(inputs) # create an embedding of the numerized numbers\n",
    "# -----> NEW LAYER ADDED ----> A Dense layer\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x) # Other options: GlobalMaxPooling1D\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "\n",
    "model_2b = tf.keras.Model(inputs, outputs, name=\"model_2b\") # construct the model\n",
    "\n",
    "# 1a. Print a model summary describing the layers and the parameters.\n",
    "model_2b.summary()\n",
    "\n",
    "# 2. Compile model -- set up the loss, optimizer, and accuracy metrics to use in training the model\n",
    "model_2b.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Train or Fit model\n",
    "model_2b_history = model_2b.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=50,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR_for_checkpoints, experiment_name=\"model_2b\")])\n",
    "\n",
    "# 3a: Test accuracy across sets\n",
    "\n",
    "model_2b_train_pred_probs = model_2b.predict(train_sentences)\n",
    "model_2b_train_preds = tf.argmax(model_2b_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2b_val_pred_probs = model_2b.predict(val_sentences)\n",
    "model_2b_val_preds = tf.argmax(model_2b_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2b_test_pred_probs = model_2b.predict(test_sentences)\n",
    "model_2b_test_preds = tf.argmax(model_2b_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = model_2b_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = model_2b_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = model_2b_test_preds, y_true = test_labels))\n",
    "\n",
    "# 4: Save Model in *.keras format\n",
    "model_2b.save(SAVE_DIR_for_entire_models + \"/Model_2b.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2c: An RNN with LSTM\n",
    "We add an LSTM layer in the middle. Two other changes from Model 2b. First, we do not need pooling anymore as it is inherent in LSTM. Second, we saw that the dense layer was not really helping so we take that out too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2c\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2c\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â        \u001b[38;5;34m49,408\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_12 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m390\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">525,062</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m525,062\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">525,062</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m525,062\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: Saved_DL_models_Exp2/Model_checkpoints/model_2c/20250118-140738\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.1615 - loss: 1.8050 - val_accuracy: 0.1780 - val_loss: 1.7862\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3263 - loss: 1.7566 - val_accuracy: 0.2120 - val_loss: 1.7846\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6071 - loss: 1.6959 - val_accuracy: 0.1840 - val_loss: 1.7745\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7002 - loss: 1.5538 - val_accuracy: 0.2700 - val_loss: 1.7141\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7312 - loss: 1.2798 - val_accuracy: 0.3480 - val_loss: 1.6067\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7602 - loss: 0.9840 - val_accuracy: 0.3820 - val_loss: 1.5794\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8512 - loss: 0.7210 - val_accuracy: 0.4240 - val_loss: 1.5809\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8908 - loss: 0.4989 - val_accuracy: 0.4200 - val_loss: 1.6845\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.3187 - val_accuracy: 0.4260 - val_loss: 1.8405\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1762 - val_accuracy: 0.4300 - val_loss: 2.0704\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0979 - val_accuracy: 0.4140 - val_loss: 2.3396\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0591 - val_accuracy: 0.4100 - val_loss: 2.5769\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 0.4080 - val_loss: 2.7807\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.4060 - val_loss: 2.9281\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 0.4140 - val_loss: 3.0420\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.4140 - val_loss: 3.1396\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.4180 - val_loss: 3.2067\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.4160 - val_loss: 3.2614\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.4160 - val_loss: 3.3063\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.4160 - val_loss: 3.3447\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.4160 - val_loss: 3.3767\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.4160 - val_loss: 3.4068\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.4140 - val_loss: 3.4386\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.4160 - val_loss: 3.4671\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.4160 - val_loss: 3.4925\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.4140 - val_loss: 3.5140\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.4160 - val_loss: 3.5311\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.4160 - val_loss: 3.5513\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.4180 - val_loss: 3.5716\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.4180 - val_loss: 3.5911\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.4180 - val_loss: 3.6100\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4160 - val_loss: 3.6283\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.4160 - val_loss: 3.6463\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.4160 - val_loss: 3.6640\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.4180 - val_loss: 3.6818\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.4200 - val_loss: 3.7001\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.4180 - val_loss: 3.7191\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.4160 - val_loss: 3.7380\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.4160 - val_loss: 3.7562\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.4180 - val_loss: 3.7735\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4160 - val_loss: 3.7902\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.4160 - val_loss: 3.8062\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.4160 - val_loss: 3.8217\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4160 - val_loss: 3.8366\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4160 - val_loss: 3.8509\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.4160 - val_loss: 3.8648\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.4160 - val_loss: 3.8783\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4160 - val_loss: 3.8913\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4160 - val_loss: 3.9039\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4160 - val_loss: 3.9161\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 41.6, 'precision': 0.48745088489941435, 'recall': 0.416, 'f1': 0.4149509882124842}\n",
      "{'accuracy': 40.699999999999996, 'precision': 0.48683727663165954, 'recall': 0.407, 'f1': 0.40473064987363994}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define or Build Model -- Define its layers (input, hidden layers, output)\n",
    "input_length = train_sentences.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_length, ), dtype=\"int\") # inputs are 1-dimensional array of input length\n",
    "x = embedding(inputs) # create an embedding of the numerized numbers\n",
    "# x = layers.Dense(128, activation=\"relu\")(x) # LAYER REMOVED -- as not helpful\n",
    "# -----> NEW LAYER ADDED ----> LSTM\n",
    "x = layers.LSTM(64)(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # LAYER REMOVED -- No longer needed\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "\n",
    "model_2c = tf.keras.Model(inputs, outputs, name=\"model_2c\") # construct the model\n",
    "\n",
    "# 1a. Print a model summary describing the layers and the parameters.\n",
    "model_2c.summary()\n",
    "\n",
    "# 2. Compile model -- set up the loss, optimizer, and accuracy metrics to use in training the model\n",
    "model_2c.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Train or Fit model\n",
    "model_2c_history = model_2c.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=50,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR_for_checkpoints, experiment_name=\"model_2c\")])\n",
    "\n",
    "# 3a: Test accuracy across sets\n",
    "\n",
    "model_2c_train_pred_probs = model_2c.predict(train_sentences)\n",
    "model_2c_train_preds = tf.argmax(model_2c_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2c_val_pred_probs = model_2c.predict(val_sentences)\n",
    "model_2c_val_preds = tf.argmax(model_2c_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2c_test_pred_probs = model_2c.predict(test_sentences)\n",
    "model_2c_test_preds = tf.argmax(model_2c_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = model_2c_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = model_2c_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = model_2c_test_preds, y_true = test_labels))\n",
    "\n",
    "# 4: Save Model in *.keras format\n",
    "model_2c.save(SAVE_DIR_for_entire_models + \"/Model_2c.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2d: An RNN with GRU\n",
    "\n",
    "Change from 2c: Just replacing the LSTM layer with a GRU layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2d\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2d\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â        \u001b[38;5;34m37,248\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_14 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m390\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512,902</span> (1.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m512,902\u001b[0m (1.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512,902</span> (1.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m512,902\u001b[0m (1.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: Saved_DL_models_Exp2/Model_checkpoints/model_2d/20250118-140813\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.1833 - loss: 1.8361 - val_accuracy: 0.2120 - val_loss: 1.7806\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1663 - loss: 1.7938 - val_accuracy: 0.2340 - val_loss: 1.7974\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1615 - loss: 1.8061 - val_accuracy: 0.0580 - val_loss: 1.8071\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1192 - loss: 1.8027 - val_accuracy: 0.0580 - val_loss: 1.8045\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1254 - loss: 1.7956 - val_accuracy: 0.1720 - val_loss: 1.7984\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1990 - loss: 1.7910 - val_accuracy: 0.2120 - val_loss: 1.7926\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1833 - loss: 1.7876 - val_accuracy: 0.2120 - val_loss: 1.7898\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2202 - loss: 1.7840 - val_accuracy: 0.2240 - val_loss: 1.7901\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2490 - loss: 1.7789 - val_accuracy: 0.2100 - val_loss: 1.7918\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2727 - loss: 1.7700 - val_accuracy: 0.2040 - val_loss: 1.7916\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4315 - loss: 1.7530 - val_accuracy: 0.2020 - val_loss: 1.7870\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5183 - loss: 1.7201 - val_accuracy: 0.2180 - val_loss: 1.7762\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6448 - loss: 1.6573 - val_accuracy: 0.2240 - val_loss: 1.7575\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6896 - loss: 1.5420 - val_accuracy: 0.2540 - val_loss: 1.7316\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7431 - loss: 1.3563 - val_accuracy: 0.2600 - val_loss: 1.7113\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7433 - loss: 1.1176 - val_accuracy: 0.2780 - val_loss: 1.7163\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7969 - loss: 0.8745 - val_accuracy: 0.2800 - val_loss: 1.7460\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8654 - loss: 0.6580 - val_accuracy: 0.2820 - val_loss: 1.7953\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9410 - loss: 0.4821 - val_accuracy: 0.2920 - val_loss: 1.8589\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.3465 - val_accuracy: 0.3020 - val_loss: 1.9226\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.2448 - val_accuracy: 0.3080 - val_loss: 1.9757\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1707 - val_accuracy: 0.3280 - val_loss: 2.0200\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1184 - val_accuracy: 0.3440 - val_loss: 2.0621\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0831 - val_accuracy: 0.3640 - val_loss: 2.1052\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0600 - val_accuracy: 0.3640 - val_loss: 2.1487\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0449 - val_accuracy: 0.3520 - val_loss: 2.1911\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 0.3560 - val_loss: 2.2311\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.3600 - val_loss: 2.2679\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.3600 - val_loss: 2.3016\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.3640 - val_loss: 2.3321\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.3620 - val_loss: 2.3599\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.3660 - val_loss: 2.3853\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.3640 - val_loss: 2.4085\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.3620 - val_loss: 2.4300\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.3620 - val_loss: 2.4499\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.3640 - val_loss: 2.4686\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.3660 - val_loss: 2.4862\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.3640 - val_loss: 2.5029\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.3640 - val_loss: 2.5188\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.3640 - val_loss: 2.5341\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.3640 - val_loss: 2.5488\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.3640 - val_loss: 2.5631\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.3640 - val_loss: 2.5768\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.3620 - val_loss: 2.5903\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.3600 - val_loss: 2.6033\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.3620 - val_loss: 2.6161\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.3620 - val_loss: 2.6287\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.3640 - val_loss: 2.6412\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.3640 - val_loss: 2.6536\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.3640 - val_loss: 2.6659\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 36.4, 'precision': 0.37808789601158743, 'recall': 0.364, 'f1': 0.35933360758339833}\n",
      "{'accuracy': 40.1, 'precision': 0.4236238117462045, 'recall': 0.401, 'f1': 0.39944644572367277}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define or Build Model -- Define its layers (input, hidden layers, output)\n",
    "input_length = train_sentences.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_length, ), dtype=\"int\") # inputs are 1-dimensional array of input length\n",
    "x = embedding(inputs) # create an embedding of the numerized numbers\n",
    "# x = layers.Dense(128, activation=\"relu\")(x) # LAYER REMOVED -- as not helpful\n",
    "# -----> NEW LAYER ADDED ----> GRU\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # LAYER REMOVED -- No longer needed\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "\n",
    "model_2d = tf.keras.Model(inputs, outputs, name=\"model_2d\") # construct the model\n",
    "\n",
    "# 1a. Print a model summary describing the layers and the parameters.\n",
    "model_2d.summary()\n",
    "\n",
    "# 2. Compile model -- set up the loss, optimizer, and accuracy metrics to use in training the model\n",
    "model_2d.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Train or Fit model\n",
    "model_2d_history = model_2d.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=50,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR_for_checkpoints, experiment_name=\"model_2d\")])\n",
    "\n",
    "# 3a: Test accuracy across sets\n",
    "\n",
    "model_2d_train_pred_probs = model_2d.predict(train_sentences)\n",
    "model_2d_train_preds = tf.argmax(model_2d_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2d_val_pred_probs = model_2d.predict(val_sentences)\n",
    "model_2d_val_preds = tf.argmax(model_2d_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2d_test_pred_probs = model_2d.predict(test_sentences)\n",
    "model_2d_test_preds = tf.argmax(model_2d_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = model_2d_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = model_2d_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = model_2d_test_preds, y_true = test_labels))\n",
    "\n",
    "# 4: Save Model in *.keras format\n",
    "model_2d.save(SAVE_DIR_for_entire_models + \"/Model_2d.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2e: A CNN\n",
    "This time, we use a Convolution layer with a pooling layer. Essentially, we just added a convolution layer in model_2a before the pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2e\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2e\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_max_pooling1d            â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â        \u001b[38;5;34m20,512\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_max_pooling1d            â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_15 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m198\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,974</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m495,974\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,974</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m495,974\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: Saved_DL_models_Exp2/Model_checkpoints/model_2e/20250118-140847\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.2463 - loss: 2.1721 - val_accuracy: 0.3140 - val_loss: 1.8433\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7727 - loss: 0.7792 - val_accuracy: 0.3400 - val_loss: 1.5684\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.2694 - val_accuracy: 0.4100 - val_loss: 1.4627\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1088 - val_accuracy: 0.4440 - val_loss: 1.4260\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0562 - val_accuracy: 0.4420 - val_loss: 1.4118\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 0.4540 - val_loss: 1.4035\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.4580 - val_loss: 1.3987\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.4680 - val_loss: 1.3961\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.4740 - val_loss: 1.3951\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.4800 - val_loss: 1.3957\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.4820 - val_loss: 1.3972\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.4800 - val_loss: 1.3992\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.4820 - val_loss: 1.4014\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.4900 - val_loss: 1.4038\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.4900 - val_loss: 1.4062\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.4880 - val_loss: 1.4087\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.4880 - val_loss: 1.4111\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.4880 - val_loss: 1.4135\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4880 - val_loss: 1.4158\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.4880 - val_loss: 1.4180\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.4880 - val_loss: 1.4201\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.4880 - val_loss: 1.4220\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.4880 - val_loss: 1.4239\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.4900 - val_loss: 1.4257\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.4900 - val_loss: 1.4274\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.4920 - val_loss: 1.4291\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.4940 - val_loss: 1.4307\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.4960 - val_loss: 1.4322\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4960 - val_loss: 1.4337\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.4960 - val_loss: 1.4351\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.4960 - val_loss: 1.4365\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4980 - val_loss: 1.4378\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4960 - val_loss: 1.4391\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.4940 - val_loss: 1.4404\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.4940 - val_loss: 1.4417\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4940 - val_loss: 1.4429\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4940 - val_loss: 1.4442\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4940 - val_loss: 1.4454\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4940 - val_loss: 1.4466\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4960 - val_loss: 1.4478\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.4960 - val_loss: 1.4490\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.4980 - val_loss: 1.4501\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5000 - val_loss: 1.4513\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5000 - val_loss: 1.4524\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5000 - val_loss: 1.4535\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5000 - val_loss: 1.4545\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5000 - val_loss: 1.4556\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5000 - val_loss: 1.4566\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5000 - val_loss: 1.4577\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5000 - val_loss: 1.4587\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 50.0, 'precision': 0.553013233374945, 'recall': 0.5, 'f1': 0.51651009579847}\n",
      "{'accuracy': 52.6, 'precision': 0.5602566288976001, 'recall': 0.526, 'f1': 0.5373783896950333}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define or Build Model -- Define its layers (input, hidden layers, output)\n",
    "input_length = train_sentences.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_length, ), dtype=\"int\") # inputs are 1-dimensional array of input length\n",
    "x = embedding(inputs) # create an embedding of the numerized numbers\n",
    "# x = layers.Dense(128, activation=\"relu\")(x) # LAYER REMOVED -- as not helpful\n",
    "# -----> NEW LAYERS ADDED ----> Conv1D + Pooling\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x) # Alt option: GlobalAveragePooling1D()(x) \n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "\n",
    "model_2e = tf.keras.Model(inputs, outputs, name=\"model_2e\") # construct the model\n",
    "\n",
    "# 1a. Print a model summary describing the layers and the parameters.\n",
    "model_2e.summary()\n",
    "\n",
    "# 2. Compile model -- set up the loss, optimizer, and accuracy metrics to use in training the model\n",
    "model_2e.compile(loss= \"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Train or Fit model\n",
    "model_2e_history = model_2e.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=50,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR_for_checkpoints, experiment_name=\"model_2e\")])\n",
    "\n",
    "# 3a: Test accuracy across sets\n",
    "\n",
    "model_2e_train_pred_probs = model_2e.predict(train_sentences)\n",
    "model_2e_train_preds = tf.argmax(model_2e_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2e_val_pred_probs = model_2e.predict(val_sentences)\n",
    "model_2e_val_preds = tf.argmax(model_2e_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "model_2e_test_pred_probs = model_2e.predict(test_sentences)\n",
    "model_2e_test_preds = tf.argmax(model_2e_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = model_2e_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = model_2e_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = model_2e_test_preds, y_true = test_labels))\n",
    "\n",
    "# 4: Save Model in *.keras format\n",
    "model_2e.save(SAVE_DIR_for_entire_models + \"/Model_2e.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Load and Use the Saved Models?\n",
    "\n",
    "We show an example of how to load the models back and use them. Below, we load the last model we developed. We check the architecture of our loaded model. As we see, they are the same as the one we had developed.\n",
    "\n",
    "Then, we check the prediction accuracies again. Once again, we find a match with our original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2e\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_2e\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_max_pooling1d            â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â       \u001b[38;5;34m475,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â        \u001b[38;5;34m20,512\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_max_pooling1d            â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_15 (\u001b[38;5;33mDense\u001b[0m)                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â           \u001b[38;5;34m198\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,487,924</span> (5.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,487,924\u001b[0m (5.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,974</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m495,974\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991,950</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m991,950\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "{'accuracy': 100.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'accuracy': 50.0, 'precision': 0.553013233374945, 'recall': 0.5, 'f1': 0.51651009579847}\n",
      "{'accuracy': 52.6, 'precision': 0.5602566288976001, 'recall': 0.526, 'f1': 0.5373783896950333}\n"
     ]
    }
   ],
   "source": [
    "new_model_2e = tf.keras.models.load_model(SAVE_DIR_for_entire_models + \"/Model_2e.keras\")\n",
    "\n",
    "# Check its architecture\n",
    "print(new_model_2e.summary())\n",
    "\n",
    "# Check prediction accuracy across sets\n",
    "\n",
    "new_model_2e_train_pred_probs = model_2e.predict(train_sentences)\n",
    "new_model_2e_train_preds = tf.argmax(new_model_2e_train_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "new_model_2e_val_pred_probs = model_2e.predict(val_sentences)\n",
    "new_model_2e_val_preds = tf.argmax(new_model_2e_val_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "new_model_2e_test_pred_probs = model_2e.predict(test_sentences)\n",
    "new_model_2e_test_preds = tf.argmax(new_model_2e_test_pred_probs, axis = 1) # Taking the most likely class as the prediction\n",
    "\n",
    "print(calculate_results(y_pred = new_model_2e_train_preds, y_true = train_labels))\n",
    "print(calculate_results(y_pred = new_model_2e_val_preds, y_true = val_labels))\n",
    "print(calculate_results(y_pred = new_model_2e_test_preds, y_true = test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Observations about the Models' Performance\n",
    "\n",
    "We see that we could not much better than the shallow ML methods. Of course, it is possible that a different network architecture could yield improvements, but it seems improbable as we tested quite a few types of models by now without seeing a gain. Possible reasons are that (1) the limited amount of training data we used and (2) the lack of information about the text contents in the documents, as our information only includes the presence or the absence of a word. We do not even have the counts of the words or the sequence in which the words occur in. Therefore, it seems that there is not enough information for our deep learning models to find \"deep\" and complex relationships.\n",
    "\n",
    "In the next section, we will incorporate the \"citation network\" (i.e., the edges between the documents) as additional information and see how it improves things. We will also turn off and on the two datastreams and see what happens, as a sort of an ablation study. Let's go then!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
